'# Basis function regression

-- Conjugate gradients solver
def solve (m:Type)?-> : m=>m=>Float -> m=>Float -> m=>Float =
  \mat b.
    x0 = for i:m. 0.0
    ax = mat **. x0
    r0 = b - ax
    (xOut, _, _) = fold (x0, r0, r0) $
       \s:m (x, r, p).
         ap = mat **. p
         alpha = vdot r r / vdot p ap
         x' = x + alpha .* p
         r' = r - alpha .* ap
         beta = vdot r' r' / (vdot r r + 0.000001)
         p' = r' + beta .* p
         (x', r', p')
    xOut

'Make some synthetic data

Nx = Fin 100
noise = 0.1
(k1, k2) = splitKey (newKey 0)

trueFun : Float -> Float =
  \x. x + sin (5.0 * x)

xs : Nx=>Float = for i. rand (ixkey k1 i)
ys : Nx=>Float = for i. trueFun xs.i + noise * randn (ixkey k2 i)

:plot zip xs ys
> <graphical output>

'Implement basis function regression

regress : (Float -> d=>Float) -> n=>Float -> n=>Float -> d=>Float =
  \featurize xRaw y.
    x = map featurize xRaw
    xT = transpose x
    solve (xT ** x) (xT **. y)

'Fit a third-order polynomial

poly : Float -> d=>Float =
  \x. for i. pow x (i2r (ordinal i))

params : (Fin 4)=>Float = regress poly xs ys

predict : Float -> Float =
  \x. vdot params (poly x)

:plot
   xsTest = linspace (Fin 100) 0.0 1.0
   zip xsTest (map predict xsTest)
> <graphical output>

'RMS error

rmsErr : n=>Float -> n=>Float -> Float =
  \truth pred. sqrt $ mean for i. sq (pred.i - truth.i)

:p rmsErr ys (map predict xs)
> 9.46494e-2
