'# Stats
Probability distributions and other functions useful for statistical computing.

'## Non-negative floating point numbers
When working with probability densities, mass functions, distributions, likelihoods, etc., we often work on a logarithmic scale to prevent floating point overflow/underflow. Working on the log scale makes `product` operations safe, since they correspond to addition on the log scale. However, when it comes to `sum` operations on the raw probability scale, care must be taken to avoid underflow by using a safe `logsumexp` function. `NonNegFloat` stores the log value internally, but is "safe" for both `sum` and `product`, since addition is implemented using the log-sum-exp trick. Several of the functions in this library return values as a `NonNegFloat`. The internally stored logarithmic value can be extracted with `get_log`, and the actual value being represented (the raw probability) can be computed with `get_raw`.

data NonNegFloat = LogFloat Float

instance Mul NonNegFloat
  mul = \(LogFloat la) (LogFloat lb). LogFloat $ la + lb
  one = LogFloat 0.0

instance Fractional NonNegFloat
  divide = \(LogFloat la) (LogFloat lb). LogFloat $ la - lb

instance Add NonNegFloat
  add = \(LogFloat la) (LogFloat lb).
    if (la > lb)
      then LogFloat $ la + log1p (exp (lb - la))
      else LogFloat $ lb + log1p (exp (la - lb))
  zero = LogFloat (-infinity)

def f_to_nnf (a:Float) : NonNegFloat = LogFloat $ log a

def get_raw ((LogFloat la):NonNegFloat) : Float = exp la

def get_log ((LogFloat la):NonNegFloat) : Float = la


'## Probability distributions
Simulation and evaluation of [probability distributions](https://en.wikipedia.org/wiki/Probability_distribution). Probability distributions implement the `Dist` interface. Distributions over an ordered space (such as typical *univariate* distributions) should also implement `OrderedDist`.

interface Dist d a
  density : d -> a -> NonNegFloat    -- either the density function or mass function
  draw : d -> Key -> a               -- function for random draws

interface [Dist d a] OrderedDist d a
  cumulative : d -> a -> NonNegFloat -- the cumulative distribution function (CDF)
  survivor : d -> a -> NonNegFloat   -- the survivor function (complement of CDF)
  quantile : d -> Float -> a         -- the quantile function (inverse CDF)

'## Univariate probability distributions
Some commonly encountered univariate distributions. 
### Bernoulli distribution
The [Bernoulli distribution](https://en.wikipedia.org/wiki/Bernoulli_distribution) is parameterised by its "success" probability, `prob`.

data BernoulliDist = Bernoulli Float

instance Dist BernoulliDist Bool
  density = \(Bernoulli prob) b.
    if b
     then LogFloat $ log prob
     else LogFloat $ log1p (-prob)
  draw = \(Bernoulli prob) k.
    rand k < prob

instance OrderedDist BernoulliDist Bool
  cumulative = \(Bernoulli prob) b.
    if b
      then LogFloat 0.0
      else LogFloat $ log1p (-prob)
  survivor = \(Bernoulli prob) b.
    if b
      then LogFloat (-infinity)
      else LogFloat $ log prob
  quantile = \(Bernoulli prob) q.
    q > (1 - prob)


'### Binomial distribution
The [binomial distribution](https://en.wikipedia.org/wiki/Binomial_distribution) is parameterised by the number of trials, `trials`, and the success probability, `prob`. Mean is `trials*prob`.

data BinomialDist = Binomial Nat Float

instance Dist BinomialDist Nat
  density = \(Binomial trials prob) x.
    if (prob == 0.0)
      then
        if (x == 0)
          then LogFloat 0.0
          else LogFloat (-infinity)
      else
        if (prob == 1.0)
          then
            if (x == trials)
              then LogFloat 0.0
              else LogFloat (-infinity)
          else
            tf = n_to_f trials
            xf = n_to_f x
            if (xf > tf)
              then LogFloat (-infinity)
              else LogFloat ( (xf * log prob) + ((tf - xf) * log1p (-prob)) +
                lgamma (tf + 1) - lgamma (xf + 1) - lgamma (tf + 1 - xf) )
  draw = \(Binomial trials prob) k.
    sum $ map b_to_n (rand_vec trials (draw $ Bernoulli prob) k)

instance OrderedDist BinomialDist Nat
  cumulative = \(Binomial trials prob) x.
    xp1:Nat = x + 1
    sum $ for i:(Fin xp1). density (Binomial trials prob) (ordinal i)
  survivor = \(Binomial trials prob) x.
    tmx = trials -| x
    sum $ for i:(Fin tmx). density (Binomial trials prob) (x + 1 + ordinal i)
  quantile = \(Binomial trials prob) q.
    tp1:Nat = trials + 1
    lpdf = for i:(Fin tp1). get_log $ density (Binomial trials prob) (ordinal i)
    cdf = cdf_for_categorical lpdf
    mi = search_sorted cdf q
    ordinal $ from_just mi


'### Exponential distribution
The [exponential distribution](https://en.wikipedia.org/wiki/Exponential_distribution) is parameterised by its *rate*, `rate > 0`, so that the mean of the distribution is `1/rate`.

data ExponentialDist = Exponential Float

instance Dist ExponentialDist Float
  density = \(Exponential rate) x.
    if (x < 0.0)
      then LogFloat (-infinity)
      else LogFloat $ log rate - (rate * x)
  draw = \(Exponential rate) k.
    log1p (-rand k) / -rate

instance OrderedDist ExponentialDist Float
  cumulative = \(Exponential rate) x.
    if (x < 0.0)
      then LogFloat (-infinity)
      else LogFloat $ log1p (-exp (-rate * x))
  survivor = \(Exponential rate) x.
    if (x < 0.0)
      then LogFloat 0.0
      else LogFloat $ -rate * x
  quantile = \(Exponential rate) q.
    log1p (-q) / -rate


'### Geometric distribution
This [geometric distribution](https://en.wikipedia.org/wiki/Geometric_distribution) is defined as the number of trials until a success (**not** the number of failures). Parameterised by success probability, `prob`. Mean is `1/prob`.

data GeometricDist = Geometric Float

instance Dist GeometricDist Nat
  density = \(Geometric prob) n.
    if (prob == 1)
      then
        if (n == 1)
          then LogFloat 0
          else LogFloat (-infinity)
      else
        nf = n_to_f n
        LogFloat $ ((nf-1)*log1p (-prob)) + log prob
  draw = \(Geometric prob) k.
    f_to_n $ ceil $ log1p (-rand k) / log1p (-prob)

instance OrderedDist GeometricDist Nat
  cumulative = \(Geometric prob) n.
    nf = n_to_f n
    LogFloat $ log1p (-pow (1-prob) nf)
  survivor = \(Geometric prob) n.
    LogFloat $ n_to_f n * log1p (-prob)
  quantile = \(Geometric prob) q.
    f_to_n $ ceil $ log1p (-q) / log1p (-prob)


'### Normal distribution
The Gaussian, or [normal distribution](https://en.wikipedia.org/wiki/Normal_distribution) is parameterised by its *mean*, `loc`, and *standard deviation*, `scale`. ie. **not** variance or precision.

data NormalDist = Normal Float Float

instance Dist NormalDist Float
  density = \(Normal loc scale) x.
    LogFloat $ -0.5 * (log (2 * pi * (sq scale)) + (sq ((x - loc) / scale)))
  draw = \(Normal loc scale) k.
    loc + (scale * randn k)

-- TODO: with some kind of "error function" (and inverse) exposed, could and should also implement OrderedDist


'### Poisson distribution
The [Poisson distribution](https://en.wikipedia.org/wiki/Poisson_distribution) is parameterised by its rate, `rate > 0`. Mean is `rate`.

data PoissonDist = Poisson Float

instance Dist PoissonDist Nat
  density = \(Poisson rate) n.
    if ((rate == 0.0)&&(n == 0))
      then
        LogFloat 0.0
      else
        nf = n_to_f n
        LogFloat $ (nf * log rate) - rate - lgamma (nf + 1)
  draw = \(Poisson rate) k.
    exp_neg_rate = exp (-rate)
    [current_k, next_k] = split_key k
    yield_state 0 \ans.
      with_state (rand current_k) \p. with_state next_k \k'.
        while do
          if get p > exp_neg_rate
            then
              [ck, nk] = split_key (get k')
              p := (get p) * rand ck
              ans := (get ans) + 1
              k' := nk
              True
            else
              False

instance OrderedDist PoissonDist Nat
  cumulative = \(Poisson rate) x.
    xp1:Nat = x + 1
    sum $ for i:(Fin xp1). density (Poisson rate) (ordinal i)
  survivor = \(Poisson rate) x.
    xp1:Nat = x + 1
    cdf = sum $ for i:(Fin xp1). density (Poisson rate) (ordinal i)
    LogFloat $ log1p (-get_raw cdf)
  quantile = \(Poisson rate) q.
    yield_state (0::Nat) \x.
      with_state 0.0 \cdf.
        while do
          cdf := (get cdf) + get_raw (density (Poisson rate) (get x))
          if (get cdf) > q
            then
              False
            else
              x := (get x) + 1
              True
  

'### Uniform distribution
The [uniform distribution](https://en.wikipedia.org/wiki/Continuous_uniform_distribution) is continuous on an interval determined by a lower bound, `low`, and upper bound, `high > low`. Mean is `(low+high)/2`.

data UniformDist = Uniform Float Float

instance Dist UniformDist Float
  density = \(Uniform low high) x.
    if (x >= low)&&(x <= high)
      then LogFloat $ -log (high - low)
      else LogFloat (-infinity)
  draw = \(Uniform low high) k.
    low + ((high - low) * rand k)

instance OrderedDist UniformDist Float
  cumulative = \(Uniform low high) x.
    if (x < low)
      then LogFloat (-infinity)
      else if (x > high)
        then LogFloat 0.0
        else LogFloat $ log (x - low) - log (high - low)
  survivor = \(Uniform low high) x.
    if (x < low)
      then LogFloat 0.0
      else if (x > high)
        then LogFloat (-infinity)
        else LogFloat $ log (high - x) - log (high - low)
  quantile = \(Uniform low high) q.
    low + ((high - low) * q)
  

'## Data summaries
Some data summary functions. Note that `mean` is provided by the prelude.

'### Summaries for vector quantities

def mean_and_variance {n a} [VSpace a, Mul a] (xs:n=>a) : (a & a) =
  m = mean xs
  ss = sum for i. sq (xs.i - m)
  v = ss / (n_to_f (size n) - 1)
  (m, v)

def variance {n a} [VSpace a, Mul a] (xs:n=>a) : a =
  snd $ mean_and_variance xs

def std_dev {n a} [VSpace a, Mul a, Floating a] (xs:n=>a) : a =
  sqrt $ variance xs

def covariance {n a} [VSpace a, Mul a] (xs:n=>a) (ys:n=>a) : a =
  xm = mean xs
  ym = mean ys
  ss = sum for i. (xs.i - xm) * (ys.i - ym)
  ss / (n_to_f (size n) - 1)

def correlation {n a} [VSpace a, Mul a, Floating a, Fractional a]
    (xs:n=>a) (ys:n=>a) : a =
  divide (covariance xs ys) (std_dev xs * std_dev ys)

'### Summaries for matrix quantities

def mean_and_variance_matrix {n d a} [VSpace a, Mul a] (xs:n=>d=>a) : (d=>a & d=>d=>a) =
  xsMean:d=>a = (for i. sum for j. xs.j.i) / n_to_f (size n)
  xsCov:d=>d=>a = (for i i'. sum for j.
                         (xs.j.i' - xsMean.i') *
                           (xs.j.i  - xsMean.i ) ) / (n_to_f (size n) - 1)
  (xsMean, xsCov)

def variance_matrix {n d a} [VSpace a, Mul a] (xs:n=>d=>a) : d=>d=>a =
  snd $ mean_and_variance_matrix xs

def correlation_matrix {n d a} [VSpace a, Mul a, Floating a, Fractional a]
    (xs:n=>d=>a) : d=>d=>a =
  cvm = variance_matrix xs
  for i. for j. divide cvm.i.j (sqrt cvm.i.i * sqrt cvm.j.j)



